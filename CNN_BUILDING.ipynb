{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tO IMPORT IMGS. IN KERAS ALL WE NEED TO DO IS TO PREP. A SPL. \n",
    "#STRUCT. FOR OUR DATASET\n",
    "\n",
    "#Step - 1 - Convolution\n",
    "#Step - 2 - Max Pooling\n",
    "#Step - 3 - Flattening\n",
    "#Step - 4 - Full Connection\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To init. our NN\n",
    "from keras.models import Sequential\n",
    "#Package used for making the first step of CNN, i.e., the convolution\n",
    "#step in which we add the convolutional layers\n",
    "#We use 2D for images and 3D for vids.\n",
    "from keras.layers import Convolution2D\n",
    "#Pooling step to add our pooling layers\n",
    "from keras.layers import MaxPooling2D\n",
    "#Convert all feature maps that we created thru convolution and max-\n",
    "#pooling into a large feature vector that becomes i/p of our fully \n",
    "#connected layers\n",
    "from keras.layers import Flatten\n",
    "#We use this package to add fully-connected layers in a classic ANN\n",
    "from keras.layers import Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Init. a CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step -1 ----- Convolution -------\n",
    "# I/p img. (interacts with) Feature Detector = Feature Map\n",
    "\n",
    "#filters arg. - The no. of feature detectors we are going to apply \n",
    "#on our i/p img.\n",
    "#Also no. of filters = no. of feature maps\n",
    "#Here we have created 32 feat. detectors of (3,3) dim.\n",
    "#Here all our i/p images will be converted into 64X64 size\n",
    "classifier.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step - 2 ------- Pooling ---------\n",
    "#Feature map  ---(Max pooling)----> Pool Feature Map\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making our NN even \"deeper\" by adding another convolutional layer\n",
    "classifier.add(Convolution2D(32,(3,3),activation='relu'))\n",
    "\n",
    "#classifier.add(Convolution2D(64,(3,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step - 3 --------- Flattening ----------\n",
    "#Pooling layer -----(Flattening)------> I/p layer of future ANN\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step - 4 -------Full Connection-------------\n",
    "\n",
    "classifier.add(Dense(units=128,activation='relu'))\n",
    "classifier.add(Dropout(0.1))\n",
    "\n",
    "classifier.add(Dense(units=128,activation='relu'))\n",
    "classifier.add(Dropout(0.1))\n",
    "\n",
    "#Output layer\n",
    "classifier.add(Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilation of CNN\n",
    "\n",
    "classifier.compile(optimizer='Adam',loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting CNN to our images\n",
    "\n",
    "#We are going to perform image augmentation that basically consists\n",
    "#of pre-processing your images to prevent overfitting\n",
    "\n",
    "#Go to keras doc.-> Preprocessing -> Image preprocessing\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "trainingset = train_datagen.flow_from_directory('/home/tejas/Desktop/DLAZ/Convolutional_Neural_Networks/dataset/training_set',\n",
    "                                                target_size=(64, 64),\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='binary')\n",
    "\n",
    "testset = test_datagen.flow_from_directory('/home/tejas/Desktop/DLAZ/Convolutional_Neural_Networks/dataset/test_set',\n",
    "                                           target_size=(64, 64),\n",
    "                                           batch_size=32,\n",
    "                                           class_mode='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 2131s 266ms/step - loss: 0.3849 - acc: 0.8155 - val_loss: 0.5310 - val_acc: 0.7980\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 2109s 264ms/step - loss: 0.1478 - acc: 0.9424 - val_loss: 0.8009 - val_acc: 0.7812\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 2104s 263ms/step - loss: 0.0878 - acc: 0.9681 - val_loss: 0.8873 - val_acc: 0.7891\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 2098s 262ms/step - loss: 0.0652 - acc: 0.9768 - val_loss: 0.8452 - val_acc: 0.7979\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 2104s 263ms/step - loss: 0.0509 - acc: 0.9818 - val_loss: 0.9621 - val_acc: 0.7871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f49c47c3eb8>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we fit our CNN to the training set\n",
    "\n",
    "#steps_per_epoch arg = no. of imgs. in our training set\n",
    "#validation_steps = no. of imgs. in our test set\n",
    "classifier.fit_generator(trainingset,steps_per_epoch=8000,\n",
    "                         epochs=5,\n",
    "                         validation_data=testset,\n",
    "                         validation_steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can improve the accuracy by making our NN even \"deeper\"\n",
    "\n",
    "#Copy Step 1 and paste after step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get better accuracy we need to choose higher target size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############  IMP. INFO ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#However, applying dropout technique to convolutional layers is not \n",
    "#commonly recommended when it comes to training deep and large \n",
    "#network. It usually gives us poor performance than the model\n",
    "#trained without dropout. There are a few of works that argued that\n",
    "#dropout over convolutional layers also gives us additional \n",
    "#performance improvement. However, its experiments were limited \n",
    "#over relatively small size datasets and networks [11]. \n",
    "#What people usually have been doing when they try to train large \n",
    "#and deep CNNs is to apply dropout to the last two or three fully\n",
    "#connected layers [7] .It turns out that this method achieved \n",
    "#state-of-art results for most of recent CNN architectures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
